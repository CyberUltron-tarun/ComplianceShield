Reference,Clause,Description ,Initial Assessment Points,Evidence/Artifact,Findings,Status
C.1,Scope,Defines the applicability and boundaries of the Artificial Intelligence Management System (AIMS) and the AI systems/services covered.,"1) Is the AIMS scope documented with clear boundaries (org units, locations, AI use-cases)?
2) Are inclusions/exclusions justified and approved?
3) Is the scope consistent across policies, risk, and audits?","AI Risk Assessment Reports, Risk Treatment Plans, Compliance Register; Internal Audit Reports, CAPA Logs, Feedback & Complaint Records, Improvement Plans",,
C.2,Normative references,"Lists external standards and documents that are indispensable for applying 42001 (e.g., ISO 22989, ISO/IEC 23894).","1) Is there a maintained register of normative references?
2) Do procedures reference the latest editions?
3) Are dependencies tracked when references change?",,,
C.3,Terms and definitions,"Adopts common AI terminology and definitions so that governance, risk, and assurance use consistent language.","1) Have key AI terms been adopted (e.g., model, dataset, drift, human-in-the-loop)?
2) Is a glossary controlled and communicated?
3) Are roles trained on these definitions?","Data Governance Policy, Training Dataset Documentation, Data Consent Records; Model Documentation, Versioning Records, Validation & Testing Reports",,
C.4,Context of the organization,"Requires understanding internal/external issues, stakeholder needs, and defining the AIMS scope accordingly.","1) Are AI-relevant issues and constraints identified (legal, ethical, societal)?
2) Are interested parties and their requirements documented?
3) Is the AIMS scope derived from that context?",,,
C.5,Leadership,"Top management demonstrates commitment, sets AI policy, assigns roles and authorities for the AIMS.","1) Is an AI policy approved and communicated?
2) Are responsibilities and authorities assigned (AIMS owner, risk, compliance)?
3) Is leadership regularly reviewing AIMS performance?","AI Policy, Governance Charter, Management Review Records; AI Risk Assessment Reports, Risk Treatment Plans, Compliance Register",,
C.6,Planning,"Plan actions to address risks/opportunities, define AI objectives, conduct risk and impact assessments, and plan changes.","1) Is there an AI risk assessment and treatment methodology?
2) Are AI objectives measurable and aligned to policy?
3) Are impact assessments planned where warranted?","AI Policy, Governance Charter, Management Review Records; AI Risk Assessment Reports, Risk Treatment Plans, Compliance Register",,
C.7,Support,"Provide resources, competence, awareness, communication, and documented information to operate the AIMS.","1) Are competencies defined for AI roles and maintained via training?
2) Are communications defined for internal/external AI matters?
3) Is documented information controlled over its lifecycle?",,,
C.8,Operation,"Operationalize plans: control lifecycle activities, perform risk/impact assessments and treatments, and maintain evidence.","1) Are lifecycle controls embedded in day-to-day workflows?
2) Are risk and impact assessments performed prior to go‑live and on change?
3) Is evidence retained for operational decisions?","AI Risk Assessment Reports, Risk Treatment Plans, Compliance Register; AI Lifecycle SOPs, Incident Logs, Monitoring Reports, Access Control Records",,
C.9,Performance evaluation,"Monitor, measure, analyze, evaluate AIMS effectiveness; conduct internal audits and management reviews.","1) Are KPIs/metrics defined for AI risk, quality, fairness, incidents?
2) Is there an audit program covering AIMS scope?
3) Are management reviews minuted with actions tracked?","AI Risk Assessment Reports, Risk Treatment Plans, Compliance Register; Internal Audit Reports, CAPA Logs, Feedback & Complaint Records, Improvement Plans",,
C.10,Improvement,Drive continual improvement; handle nonconformities and corrective actions related to AIMS and AI systems.,"1) Are nonconformities recorded with root cause and CAPA?
2) Are lessons learned from incidents/near misses applied?
3) Is there a continual improvement log with owners and dates?",,,
A.1,General — Objective (not a control),Annex A introductory guidance and context. This is not an implementable control. [Objective – not a control],N/A — objective (not a control),,,
A.2.1,Policies related to AI — Objective (not a control),Define the objective and outcome for AI policies. Controls follow at A.2.2–A.2.4. [Objective – not a control],N/A — objective (not a control),,,
A.2.2,AI policy,"Establish and maintain an AI policy that states objectives, principles, and guardrails for AI development, procurement, and use.","1) Is a formal AI policy published and in force?
2) Does it cover ethics, risk, security, and oversight?
3) Is it approved by top management and reviewed regularly?",,,"AI Policy, Governance Charter, Management Review Records; AI Risk Assessment Reports, Risk Treatment Plans, Compliance Register"
A.2.3,Alignment with other organizational policies,"Ensure the AI policy aligns with security, privacy, quality, safety, and legal policies to avoid conflicts and gaps.","1) Is the AI policy mapped to security/privacy/quality policies?
2) Are conflicts reconciled and documented?
3) Are downstream procedures updated accordingly?",,,"AI Policy, Governance Charter, Management Review Records"
A.2.4,Review of the AI policy,Review the AI policy at planned intervals or upon significant change to maintain suitability and effectiveness.,"1) Is there a defined review cadence and triggers?
2) Are stakeholder inputs considered during review?
3) Are changes communicated and version‑controlled?",,,"AI Policy, Governance Charter, Management Review Records"
A.3.1,Internal organization — Objective (not a control),Define the objective and outcome for internal AI governance and organization. Controls follow at A.3.2–A.3.3. [Objective – not a control],N/A — objective (not a control),,,
A.3.2,AI roles and responsibilities,"Define and assign roles for AI governance, risk, lifecycle, monitoring, and escalation; ensure accountability.","1) Are roles (AIMS owner, model risk lead, data steward, HIL operators) defined?
2) Are authorities and decision rights clear?
3) Are deputies and segregation of duties established?",,,"AI Risk Assessment Reports, Risk Treatment Plans, Compliance Register; Data Governance Policy, Training Dataset Documentation, Data Consent Records; Model Documentation, Versioning Records, Validation & Testing Reports; Roles & Responsibilities Matrix, Accountability Matrix, Decision Logs"
A.3.3,Reporting of concerns,"Provide channels for reporting AI-related concerns (bias, safety, misuse) and ensure non‑retaliation and timely handling.","1) Are confidential reporting channels available to staff and users?
2) Are concerns triaged and tracked to closure?
3) Are trends analyzed and fed into improvements?",,,
A.4.1,Resources for AI systems — Objective (not a control),Define the objective and outcome for resourcing AI systems. Controls follow at A.4.2–A.4.6. [Objective – not a control],N/A — objective (not a control),,,
A.4.2,Resource documentation,"Maintain an inventory of AI system components and resources (models, datasets, tools, environments, people).","1) Is there an up‑to‑date AI asset inventory?
2) Are owners, versions, and dependencies recorded?
3) Is criticality and risk rating captured?",,,"AI Risk Assessment Reports, Risk Treatment Plans, Compliance Register; Data Governance Policy, Training Dataset Documentation, Data Consent Records; Model Documentation, Versioning Records, Validation & Testing Reports"
A.4.3,Data resources,"Document data sources, licenses, constraints, and retention for datasets used in AI systems.","1) Are data sources and usage rights documented?
2) Are data sensitivity and residency tracked?
3) Are retention/disposal rules defined and applied?",,,"Data Governance Policy, Training Dataset Documentation, Data Consent Records"
A.4.4,Tooling resources,"Track tools and platforms used in the AI lifecycle (frameworks, libraries, MLOps, evaluation tools), including security posture.","1) Are tooling versions and suppliers recorded?
2) Are vulnerabilities and end‑of‑support monitored?
3) Are approved toolchains defined for production use?",,,
A.4.5,System and computing resources,"Record compute, storage, accelerators, and runtime environments; ensure capacity and resilience meet risk appetite.","1) Are environments (dev/test/prod) defined and controlled?
2) Is capacity/resilience planning documented?
3) Are access controls and isolation enforced?",,,"AI Risk Assessment Reports, Risk Treatment Plans, Compliance Register"
A.4.6,Human resources,"Ensure personnel with AI responsibilities have appropriate competence, training, and time; address role-specific ethics/risks.","1) Are competency requirements defined and assessed?
2) Are training plans maintained for AI roles?
3) Are key person risks mitigated?",,,"AI Risk Assessment Reports, Risk Treatment Plans, Compliance Register"
A.5.1,Assessing impacts of AI systems — Objective (not a control),Define the objective and outcome for AI impact assessment. Controls follow at A.5.2–A.5.5. [Objective – not a control],N/A — objective (not a control),,,
A.5.2,AI system impact assessment process,"Establish a process to assess impacts on individuals, groups, and society across the AI system lifecycle.","1) Is there a defined impact assessment workflow with gates?
2) Are high‑risk uses escalated for enhanced review?
3) Are mitigations linked to risks and re‑assessed after change?",,,"AI Risk Assessment Reports, Risk Treatment Plans, Compliance Register"
A.5.3,Documentation of impact assessments,"Maintain records of impact assessments, decisions, mitigations, and approvals.","1) Are assessments version‑controlled with rationale?
2) Are dissenting opinions and conditions captured?
3) Is evidence retained per retention rules?",,,
A.5.4,Assessing impacts on individuals/groups,"Evaluate effects on rights, fairness, explainability, and safety for affected persons or groups.","1) Are bias/fairness and explainability examined for impacted groups?
2) Are human oversight and redress mechanisms defined?
3) Are accessibility and inclusion considered?",,,
A.5.5,Assessing societal impacts,"Consider broader societal, environmental, and economic impacts, including dual‑use and systemic risks.","1) Are systemic, environmental, and dual‑use risks assessed?
2) Are external stakeholders consulted where appropriate?
3) Are monitoring triggers defined for post‑deployment?",,,"AI Risk Assessment Reports, Risk Treatment Plans, Compliance Register"
A.6.1.1,AI system life cycle — Responsible development objective (not a control),Define the objective and outcome for responsible development. Controls follow at A.6.1.2–A.6.1.3. [Objective – not a control],N/A — objective (not a control),,,
A.6.1.2,Objectives for responsible development,"Define objectives and criteria that guide responsible AI design and development (safety, security, fairness, performance).","1) Are measurable development objectives set with thresholds?
2) Are trade‑offs documented and approved?
3) Are objectives mapped to tests and acceptance criteria?",,,
A.6.1.3,Processes for responsible design and development,"Establish processes (requirements, design reviews, threat modeling, safety cases) to embed responsibility into development.","1) Are SDL/ML lifecycle processes documented and followed?
2) Are threat/safety models maintained and reviewed?
3) Are independence and peer reviews performed?",,,"Model Documentation, Versioning Records, Validation & Testing Reports"
A.6.2.1,AI system life cycle — Lifecycle management objective (not a control),Define the objective and outcome for lifecycle management. Controls follow at A.6.2.2–A.6.2.8. [Objective – not a control],N/A — objective (not a control),,,
A.6.2.2,Requirements and specification,"Define AI system requirements (intended use, performance, safety, human oversight, data, compliance) and keep them current.","1) Are requirements traced to risks and objectives?
2) Are constraints (legal, ethical, domain) captured?
3) Is change control applied to requirements?",,,"AI Risk Assessment Reports, Risk Treatment Plans, Compliance Register; Data Governance Policy, Training Dataset Documentation, Data Consent Records"
A.6.2.3,Design/development documentation,"Maintain design and development documentation sufficient for understanding, assurance, and audit.","1) Are model cards/design docs maintained and reviewed?
2) Are datasets, features, and preprocessing documented?
3) Are evaluation protocols recorded?",,,"Data Governance Policy, Training Dataset Documentation, Data Consent Records; Model Documentation, Versioning Records, Validation & Testing Reports; Internal Audit Reports, CAPA Logs, Feedback & Complaint Records, Improvement Plans"
A.6.2.4,Verification and validation,"Plan and perform verification/validation including robustness, safety, security, privacy, and fairness testing.","1) Are test strategies defined (unit, integration, adversarial, red‑teaming)?
2) Are acceptance criteria defined with go/no‑go gates?
3) Are independent validations used for high‑risk systems?",,,"AI Risk Assessment Reports, Risk Treatment Plans, Compliance Register"
A.6.2.5,Deployment,"Control deployment with approvals, environment readiness, rollback strategies, and monitoring hooks.","1) Are deployment checklists and approvals enforced?
2) Are rollbacks and canary/guardrails defined?
3) Are monitoring/telemetry enabled at go‑live?",,,
A.6.2.6,Operation and monitoring,"Operate AI systems with monitoring for drift, performance, safety/security signals, and user feedback loops.","1) Are KPIs/SLOs and thresholds defined for alerts?
2) Is model/data drift monitored with retraining triggers?
3) Are user issue channels integrated into ops?",,,"Data Governance Policy, Training Dataset Documentation, Data Consent Records; Model Documentation, Versioning Records, Validation & Testing Reports"
A.6.2.7,Technical documentation,"Maintain technical documentation sufficient for operation, maintenance, transfer, and audit of AI systems.","1) Is operational documentation complete and current?
2) Are handover packages built for maintainers?
3) Is access to docs controlled and auditable?",,,"AI Lifecycle SOPs, Incident Logs, Monitoring Reports, Access Control Records; Internal Audit Reports, CAPA Logs, Feedback & Complaint Records, Improvement Plans"
A.6.2.8,Event logging,"Record events to support traceability, incident investigation, accountability, and continuous improvement.","1) Are inputs/outputs/decisions and key events logged with context?
2) Is log integrity protected and retention defined?
3) Are privacy and minimization respected in logs?",,,"Roles & Responsibilities Matrix, Accountability Matrix, Decision Logs"
A.7.1,Data for AI systems — Objective (not a control),Define the objective and outcome for data used by AI systems. Controls follow at A.7.2–A.7.6. [Objective – not a control],N/A — objective (not a control),,,"Data Governance Policy, Training Dataset Documentation, Data Consent Records"
A.7.2,Data for development and enhancement,"Define rules for generating, selecting, and updating datasets used to develop and enhance AI systems.","1) Are dataset selection and update criteria documented?
2) Are synthetic/augmented data controls defined?
3) Are harmful data patterns identified and mitigated?",,,"Data Governance Policy, Training Dataset Documentation, Data Consent Records"
A.7.3,Acquisition of data,"Control data acquisition methods, provenance, licensing, and lawful basis.","1) Are sources vetted for legitimacy and rights?
2) Are data collection notices and consents tracked?
3) Are scraping/third‑party feeds assessed for risk?",,,"AI Risk Assessment Reports, Risk Treatment Plans, Compliance Register; Data Governance Policy, Training Dataset Documentation, Data Consent Records"
A.7.4,Data quality for AI systems,"Define and monitor data quality requirements (accuracy, completeness, representativeness) appropriate to risk.","1) Are quality metrics/thresholds defined by use case?
2) Are sampling and labeling quality managed?
3) Are bias and representativeness monitored over time?",,,"AI Risk Assessment Reports, Risk Treatment Plans, Compliance Register; Data Governance Policy, Training Dataset Documentation, Data Consent Records"
A.7.5,Data provenance,Maintain lineage for data used by AI systems including transformations and derivations.,"1) Is lineage captured from source to model input?
2) Are transformations versioned and reproducible?
3) Are provenance gaps risk‑assessed?",,,"AI Risk Assessment Reports, Risk Treatment Plans, Compliance Register; Data Governance Policy, Training Dataset Documentation, Data Consent Records; Model Documentation, Versioning Records, Validation & Testing Reports"
A.7.6,Data preparation,"Control data preparation (cleaning, labeling, anonymization) with security and privacy safeguards.","1) Are preparation steps documented and approved?
2) Are privacy‑preserving techniques applied where needed?
3) Are labeling guidelines and QA in place?",,,"Data Governance Policy, Training Dataset Documentation, Data Consent Records"
A.8.1,Information for interested parties — Objective (not a control),Define the objective and outcome for information provided to interested parties. Controls follow at A.8.2–A.8.5. [Objective – not a control],N/A — objective (not a control),,,
A.8.2,System documentation & user information,"Provide users with key information about purpose, capabilities/limits, risks, and required operating conditions.","1) Are model/system cards or user guidance available?
2) Are limitations, uncertainty, and HIL requirements clear?
3) Is change history communicated to users?",,,"AI Risk Assessment Reports, Risk Treatment Plans, Compliance Register; Model Documentation, Versioning Records, Validation & Testing Reports"
A.8.3,External reporting,"Establish processes for external reporting (regulatory filings, disclosures) appropriate to risk and jurisdiction.","1) Are required regulatory disclosures identified?
2) Is reporting accurate, timely, and approved?
3) Are records of submissions retained?",,,"AI Risk Assessment Reports, Risk Treatment Plans, Compliance Register"
A.8.4,Communication of incidents,"Define how AI‑related incidents are communicated to interested parties, with timelines and responsibilities.","1) Are thresholds and timelines for notification defined?
2) Are contact lists and message templates maintained?
3) Are post‑incident updates and lessons learned shared?",,,
A.8.5,Information for interested parties,"Provide additional information to enable third parties to assess risks and impacts, balancing transparency and security.","1) Is a process to respond to stakeholder information requests defined?
2) Are confidentiality/privacy limits respected?
3) Is information quality reviewed before release?",,,"AI Risk Assessment Reports, Risk Treatment Plans, Compliance Register; Transparency Statements, Explainability Reports, User Communication Records"
A.9.1,Use of AI systems — Objective (not a control),Define the objective and outcome for responsible use. Controls follow at A.9.2–A.9.4. [Objective – not a control],N/A — objective (not a control),,,
A.9.2,Processes for responsible use,"Define and enforce processes for responsible use of AI in operations, procurement, and product features.","1) Are use‑approval workflows defined with criteria?
2) Are prohibited/restricted uses documented?
3) Are periodic use reviews performed?",,,"AI Lifecycle SOPs, Incident Logs, Monitoring Reports, Access Control Records"
A.9.3,Objectives for responsible use,"Set objectives for responsible use (safety, fairness, transparency) and measure adherence.","1) Are use objectives measurable and tracked?
2) Are dashboards reviewed by governance bodies?
3) Are corrective actions taken when objectives are missed?",,,"Transparency Statements, Explainability Reports, User Communication Records"
A.9.4,Intended use of the AI system,Define intended use and ensure use remains within that purpose; manage changes to intended use via governance.,"1) Is intended use documented and communicated?
2) Are off‑label uses prevented or escalated?
3) Are change impacts assessed before expanding use?",,,
A.10.1,Third‑party and customer relationships — Objective (not a control),Define the objective and outcome for third‑party and customer relationships. Controls follow at A.10.2–A.10.4. [Objective – not a control],N/A — objective (not a control),,,
A.10.2,Allocating responsibilities,"Define shared responsibilities with third parties across the AI lifecycle (provider, developer, deployer, user).","1) Are RACI/responsibility matrices agreed in contracts?
2) Are oversight and audit rights defined?
3) Are exit/transition plans in place?",,,"Internal Audit Reports, CAPA Logs, Feedback & Complaint Records, Improvement Plans"
A.10.3,Suppliers,"Manage supplier risk for AI components/services, including assurance over models, data, and platforms.","1) Are due diligence and ongoing assessments performed?
2) Are SLAs/SLOs and security/ethics clauses enforced?
3) Are vulnerability and incident disclosures required?",,,"AI Risk Assessment Reports, Risk Treatment Plans, Compliance Register; Data Governance Policy, Training Dataset Documentation, Data Consent Records; Model Documentation, Versioning Records, Validation & Testing Reports"
A.10.4,Customers,Define responsibilities and information provided to customers to enable responsible and compliant use.,"1) Are customer obligations and safe‑use guidance documented?
2) Are support channels and escalation paths defined?
3) Are misuse/breach terms and remedies defined?",,,