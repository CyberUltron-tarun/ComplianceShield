Reference,Clause,Description,Initial Assessment Points
1,Governance & Oversight,"Governance ensures that A/IS remain human-centric, aligned with values and ethical principles, not just technical goals. It requires societal and policy guidelines so that systems behave beneficially, fostering trust between people and technology. Calls on technical communities to practice self-reflection and embed ethics into institutions, design processes, and oversight mechanisms.","1. Has the organization appointed an AI Ethics Officer or Committee?
2. Has an AI ethics committee/board been created to oversee A/IS design?
3. Are ethical responsibilities clearly assigned (designers, operators, owners)?
4. Are accountability structures aligned with IEEE P7000 standards?
5. Is there a defined escalation path for ethical risk incidents?"
2,Human Rights & Well-Being,"Autonomous and intelligent systems (A/IS) must be designed to honor internationally recognized human rights, including dignity, freedoms, equality, and cultural diversity. Systems must be safe, secure, and traceable so that any harms can be investigated and corrected.",1. Does every AI project undergo a human rights impact assessment?
3,Accountability & Transparency,"Designers, manufacturers, owners, and operators of A/IS must be responsible and accountable for system outcomes. Because A/IS can be opaque, accountability requires clear frameworks and programmatic-level auditability. Liability may need to be shared across multiple responsible parties. Accountability is closely linked to Transparency, since demonstrating responsibility depends on visibility into system behavior.","1. Are AI systems documented with datasets, testing, and design decisions?"
4,Human Rights,"Autonomous and intelligent systems (A/IS) must be designed to honor internationally recognized human rights, including dignity, freedoms, equality, and cultural diversity. Systems must be safe, secure, and traceable so that any harms can be investigated and corrected.","1. Do systems respect internationally recognized human rights (privacy, dignity, freedom)?
2. Is there a review mechanism to detect potential human rights infringements?
3. Are vulnerable groups specifically protected in system design?"
5,Well-being,"The guiding goal of A/IS should be to prioritize human flourishing (eudaimonia). Rather than focusing solely on economic measures like GDP, systems should be evaluated against social, psychological, and environmental well-being indicators such as the OECD Better Life Index, the Happy Planet Index, and Bhutanâ€™s Gross National Happiness. Well-being is positioned as a higher virtue in design, advancing sustainability, equity, and happiness.","1. Have well-being metrics (psychological, social, environmental) been defined (IEEE P7010)?
2. Are AI projects evaluated against their contribution to human flourishing (not just GDP)?
3. Do systems enhance equitable access to resources and opportunities?"
6,Accountability,"Designers, manufacturers, owners, and operators of A/IS must be responsible and accountable for system outcomes. Because A/IS can be opaque, accountability requires clear frameworks and programmatic-level auditability. Liability may need to be shared across multiple responsible parties. Accountability is closely linked to Transparency, since demonstrating responsibility depends on visibility into system behavior.","1. Is there an audit trail for critical AI decision-making processes?
2. Can system decisions be traced back to accountable humans or organizations?
3. Are liability frameworks documented for when AI causes harm?"
7,Transparency,"A/IS should operate in ways that allow traceability, auditability, and explainability. Individuals should always know when they are interacting with an AI system. In high-stakes areas like government and justice, transparency also means supporting external oversight. Transparency is essential for accountability and building public trust.","1. Are system logic, datasets, and models explainable to stakeholders?
2. Do users receive disclosure when interacting with AI?
3. Are government/justice-related AI systems open to external oversight and verification?"
8,Awareness & Misuse Prevention,"A/IS must be designed and managed to minimize risks of misuse, whether intentional abuse or unintended harmful outcomes. This includes preparing against adversarial attacks, dual-use risks, and data poisoning. Ethical risk assessment should explicitly include worst-case misuse scenarios and implement preventive safeguards.","1. Have risk scenarios (misuse, adversarial attacks, dual-use risks) been mapped?
2. Is there a monitoring system for unintended harmful outcomes?
3. Do security protocols address adversarial manipulation (e.g., data poisoning, deepfakes)?"
9,Personal Data Rights,"Individuals must have control over access and use of their personal data. Principles include consent, purpose limitation, minimization, retention limits, and restrictions on resale. The EAD emphasizes privacy-by-design and frameworks like IEEE P7002 to operationalize ethical data governance.","1. Do individuals control access to their data (opt-in/consent)?
2. Are data minimization and privacy-by-design applied (align with IEEE P7002)?
3. Are retention and resale of personal data explicitly governed?"
10,Education & Awareness,"Effective ethics in A/IS depends on capacity-building for multiple stakeholders: training for engineers and developers in ethical design; public education to understand impacts of AI; and policy-makers gaining technical and ethical literacy to govern responsibly. Encourages inclusive, global awareness efforts.","1. Is the workforce trained on A/IS ethics?
2. Is the public educated about the implications of AI systems?
3. Are policymakers engaged with technical/ethical training?"
11,Legal & Policy Frameworks,"Legal principles must ensure safety, rights protection, and accountability in A/IS. Defines which decisions must remain under meaningful human control. Liability frameworks should apportion responsibility appropriately when harm occurs. Law and policy must incorporate transparency, safety, and human rights obligations.","1. Have clear rules been established on which decisions must remain under human control?
2. Are liability allocation frameworks aligned with existing laws?
3. Do regulations incorporate transparency, safety, and human rights?"
12,Technology-Specific Concerns (Autonomous Weapons),"Autonomous weapons require meaningful human control, audit trails, explainability for operators, professional ethical codes, and operator training. Safeguards must ensure compliance with humanitarian law and ethics.","1. Is meaningful human control retained?
2. Do audit logs ensure accountability in weapons systems?"
13,Technology-Specific Concerns (AGI/ASI),"Artificial General Intelligence (AGI) and Artificial Superintelligence (ASI) carry considerable risks. Unanticipated behavior could become dangerous, and not all AGI architectures can align with human interests. Governance and careful evaluation are critical before deployment.",1. Are governance and safety research applied to advanced AI models?
14,Technology-Specific Concerns (Affective Computing),"Affective computing and emotional AI must not manipulate or distort human emotions. Even early systems already shape public perception, so safeguards are essential to protect autonomy and psychological integrity.",1. Is emotional AI designed to avoid manipulation?
15,Technology-Specific Concerns (Mixed Reality),"Mixed reality technologies raise ethical concerns about identity, autonomy, and rights, especially with real-time personalization and integration into daily life. Systems must protect usersâ€™ control over their multifaceted identities and ensure psychological well-being.",1. Does system design protect identity and agency in virtual environments?
