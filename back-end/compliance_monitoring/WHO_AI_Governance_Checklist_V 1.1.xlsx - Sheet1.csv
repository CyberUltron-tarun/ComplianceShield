Phase,Reference,Clause,Description,Audit Questions,Evidence/Artifact,Findings,Status
Deployment,Affordability & inequality,Ensure accessibility and fair pricing,"Require inclusive pricing models, multi-language support, and low-cost access in LMICs.",Are cost and language barriers addressed to ensure fair access to LMMs?,Data governance framework; Dataset documentation (datasheets); Provenance/lineage records; Data quality checks; Anonymization logs,,
Development,Bias & misinformation,Audit datasets for bias & misinformation,"Systematic review of sources to detect hidden prejudices, mislabeling, and false data. Helps avoid 'hallucinations' and discriminatory outputs.",Has a formal bias and misinformation audit been conducted on training datasets?,Data governance framework; Dataset documentation (datasheets); Provenance/lineage records; Data quality checks; Anonymization logs,,
Development,Biased/incomplete training data,Ensure legality and representativeness of training data,"Data must be lawfully obtained, consented, and representative of diverse populations (age, gender, race, disability, LMICs). Prevent over-reliance on Western-centric datasets.","Are training datasets legally obtained, consented, and representative of diverse populations?",Compliance register; Legal basis & consent forms; DPIA/PIA reports; Data sharing agreements; Regulatory correspondence,,
Provision,Black-box models,Provide explainability & interpretability,Enable clinicians and regulators to understand why the model made a decision.,Can model outputs be explained in terms understandable to clinicians and patients?,Compliance register; Legal basis & consent forms; DPIA/PIA reports; Data sharing agreements; Regulatory correspondence,,
Liability,Blurred accountability,Define clear liability allocation,"Clarify roles of developers, providers, and deployers for accountability.","Are roles and liabilities defined between developers, providers, and deployers?",Ethics principle mapping (WHO/UN/OECD); Ethical risk assessment; Bias/fairness test reports; Accountability framework,,
Deployment,Clinician skill degradation,Provide healthcare worker training,"Train clinicians on AI use, bias recognition, cybersecurity risks, and balanced judgment.","Are clinicians trained to identify AI bias, errors, and cybersecurity risks?",Privacy policy & notices; Consent records; De-identification procedures; Access controls to personal data; Privacy by Design checklists,,
International Governance,Competitive distortions,Avoid uneven regulations,Prevent certain jurisdictions from giving unfair advantages to companies.,Are regulations harmonized to prevent competitive distortions?,AI Governance Charter/Policy; Steering Committee minutes; RACI/role definitions; Risk appetite statement; Annual governance plan,,
Provision,Consumer harm,Apply consumer protection laws,"Guard against misleading claims, false advertising, or unsafe experimental use.",Does the product comply with consumer protection laws to prevent harm?,Compliance register; Legal basis & consent forms; DPIA/PIA reports; Data sharing agreements; Regulatory correspondence,,
Deployment,Cybersecurity,Implement robust protections,"Defend against adversarial attacks, data leaks, and manipulation of LMM outputs.",Are cybersecurity protocols implemented against adversarial attacks and data breaches?,Data governance framework; Dataset documentation (datasheets); Provenance/lineage records; Data quality checks; Anonymization logs,,
Provision,Early experimentation risks,Use regulatory sandboxes,Controlled test environments allow real-world trials while limiting patient exposure.,Was the model tested in a regulatory sandbox before full rollout?,Compliance register; Legal basis & consent forms; DPIA/PIA reports; Data sharing agreements; Regulatory correspondence,,
Development,Environmental footprint,Monitor carbon & water usage,"Track compute energy, carbon footprint, and water consumption. Invest in efficiency improvements.",Is the environmental impact (carbon/water footprint) of LMM development measured and reported?,Compliance register; Legal basis & consent forms; DPIA/PIA reports; Data sharing agreements; Regulatory correspondence,,
International Governance,Environmental impact,Monitor carbon & water globally,Track and regulate AI’s environmental footprint at an international scale.,Is the global environmental footprint of AI tracked and reported?,AI Governance Charter/Policy; Steering Committee minutes; RACI/role definitions; Risk appetite statement; Annual governance plan,,
Development,Exploitation of workers,Address labour conditions for data annotators,"Pay fair wages, provide psychological support, and avoid exploitative crowdwork conditions.",Are data annotators compensated fairly and provided with psychological support?,Data governance framework; Dataset documentation (datasheets); Provenance/lineage records; Data quality checks; Anonymization logs,,
Liability,Harm caused by AI,Introduce strict liability standards,Make developers/providers legally responsible for harm unless proven otherwise.,Is strict liability established for harm caused by LMMs in healthcare?,Compliance register; Legal basis & consent forms; DPIA/PIA reports; Data sharing agreements; Regulatory correspondence,,
Deployment,Harm to patients,Establish error management & redress,Clear mechanisms for reporting AI errors and compensating harmed patients.,Is there a defined process for reporting AI errors and compensating patients?,Model documentation (model cards); Training/validation datasets & splits; Performance benchmark results; Versioning/change logs,,
International Governance,High-income dominance,Ensure LMIC representation,"Include low- and middle-income countries, not just wealthy nations and big tech.",Are LMICs included in AI governance and policy-making forums?,AI Governance Charter/Policy; Steering Committee minutes; RACI/role definitions; Risk appetite statement; Annual governance plan,,
International Governance,Human rights risks,Align with international law,"Ensure AI upholds privacy, dignity, autonomy, and equity under global treaties.",Are AI systems aligned with human rights and international legal frameworks?,AI Governance Charter/Policy; Steering Committee minutes; RACI/role definitions; Risk appetite statement; Annual governance plan,,
Deployment,Inappropriate use,Validate LMM use-cases,"Hospitals, ministries, and providers must assess suitability of each AI application for health context.",Has the AI application’s suitability for clinical/administrative tasks been validated?,Clinical safety case; Hazard analysis (FMEA/Fault tree); Adverse event register; RCA reports; Mitigation plans,,
Provision,Lack of accountability,Publish impact assessments,"Providers must assess societal, ethical, and patient risks and disclose results publicly.",Are ethical and societal impact assessments published openly before release?,Ethics principle mapping (WHO/UN/OECD); Ethical risk assessment; Bias/fairness test reports; Accountability framework,,
International Governance,Lack of coordination,Promote cross-border cooperation,"Enable global data-sharing standards, harmonized audits, and best practices.","Is cross-border cooperation in AI safety, audits, and standards established?",AI Governance Charter/Policy; Steering Committee minutes; RACI/role definitions; Risk appetite statement; Annual governance plan,,
Development,Lack of transparency - 1,Disclose training data sources & methodology,"Provide documentation showing dataset origins, cleaning steps, and known limitations, to improve explainability.",Are data sources and methodologies transparently documented and accessible to regulators?,Compliance register; Legal basis & consent forms; DPIA/PIA reports; Data sharing agreements; Regulatory correspondence,,
Provision,Lack of transparency - 2,Publish explainable documentation,"Disclose architecture, training data sources, and known risks in simple terms for clinicians/patients.","Is model documentation intelligible to clinicians, patients, and regulators?",Compliance register; Legal basis & consent forms; DPIA/PIA reports; Data sharing agreements; Regulatory correspondence,,
Deployment,Lack of transparency - 3,Maintain operational disclosures,"Publish logs, performance reports, and documentation on AI use in patient care.",Are deployment logs and performance reports maintained and published?,Model documentation (model cards); Training/validation datasets & splits; Performance benchmark results; Versioning/change logs,,
Deployment,Lack of trust,Engage public in governance,"Run community consultations, AI literacy programs, and cultural acceptability assessments.",Are communities consulted on AI acceptability and involved in AI literacy initiatives?,AI Governance Charter/Policy; Steering Committee minutes; RACI/role definitions; Risk appetite statement; Annual governance plan,,
Liability,Limited redress,Consider no-fault compensation funds,Compensation schemes ensure fair redress for harm without lengthy legal battles.,Is there a no-fault compensation scheme for AI-related harm?,Compliance register; Legal basis & consent forms; DPIA/PIA reports; Data sharing agreements; Regulatory correspondence,,
Development,Monopoly risks,Promote open-source/transparent models,Encourage open research or public–private collaborations to avoid exclusive control by big tech.,Are models or documentation made available under open-source or transparent licensing schemes?,Model documentation (model cards); Training/validation datasets & splits; Performance benchmark results; Versioning/change logs,,
Provision,Over-reliance on automation,Maintain human-in-the-loop,Ensure AI recommendations are always subject to clinician review and oversight.,Is clinician oversight mandated for all LMM-driven clinical decisions?,AI Governance Charter/Policy; Steering Committee minutes; RACI/role definitions; Risk appetite statement; Annual governance plan,,
Deployment,Patient awareness,Inform patients about AI use,Ensure patients know when AI is assisting in diagnosis or treatment.,Are patients informed when AI assists in diagnosis or treatment?,Deployment architecture; MLOps pipeline controls; CI/CD logs; Environment baselines; Access controls,,
Liability,Patient burden of proof,Apply presumption of causality,Shift burden from patients to providers if harm occurs.,Does liability law presume AI involvement unless proven otherwise?,Compliance register; Legal basis & consent forms; DPIA/PIA reports; Data sharing agreements; Regulatory correspondence,,
Deployment,Post-deployment risks,Conduct independent audits,"Regular external reviews ensure real-world safety, accuracy, and bias detection.",Are regular external audits performed to verify ongoing model safety and fairness?,Ethics principle mapping (WHO/UN/OECD); Ethical risk assessment; Bias/fairness test reports; Accountability framework,,
Provision,Privacy breaches,Enforce safeguards for user-inputted data,"Ensure secure handling of personal health information, with encryption and consent tracking.","Are user health data encrypted, anonymized, and protected by strict retention rules?",Compliance register; Legal basis & consent forms; DPIA/PIA reports; Data sharing agreements; Regulatory correspondence,,
Development,Privacy violations,Conduct Data Protection Impact Assessments (DPIAs),"Before model training, evaluate risks to privacy, data sharing, and potential harm. DPIAs ensure compliance with GDPR-like laws and patient consent frameworks.","Is a DPIA documented, reviewed, and approved before training begins?",Compliance register; Legal basis & consent forms; DPIA/PIA reports; Data sharing agreements; Regulatory correspondence,,
Development,Programmer ethics,Provide certification/training,"Ensure engineers are trained in medical ethics, patient safety, and data protection.",Do developers undergo ethics and patient-safety training before working on LMMs?,Ethics principle mapping (WHO/UN/OECD); Ethical risk assessment; Bias/fairness test reports; Accountability framework,,
International Governance,Regulatory gaps,Build UN-led governance frameworks,Global AI rules prevent fragmented or inconsistent regulations across borders.,Are international frameworks for AI governance being adopted?,AI Governance Charter/Policy; Steering Committee minutes; RACI/role definitions; Risk appetite statement; Annual governance plan,,
Provision,Risk of harm to patients,Require third-party audits,"Independent audits verify accuracy, fairness, and compliance with health regulations.",Have independent third-party audits been conducted before model deployment?,Ethics principle mapping (WHO/UN/OECD); Ethical risk assessment; Bias/fairness test reports; Accountability framework,,
Development,Stakeholder inclusiveness,Involve diverse groups in design,"Engage patients, clinicians, ethicists, disability advocates in early design stages.","Were stakeholders (patients, clinicians, ethicists, disability groups) involved in model design?",Ethics principle mapping (WHO/UN/OECD); Ethical risk assessment; Bias/fairness test reports; Accountability framework,,
Provision,System-wide bias,Obtain regulatory approval & certification,"Models used in health must be certified like medical devices, ensuring safety, equity, and compliance.",Has the model received certification as a medical-grade device where applicable?,Compliance register; Legal basis & consent forms; DPIA/PIA reports; Data sharing agreements; Regulatory correspondence,,
Provision,Unethical use,Mandate ethical & human rights standards,Align provision with WHO’s six AI ethics principles; prohibit harmful deployments.,Are ethical and human rights principles applied in provision contracts and policies?,Ethics principle mapping (WHO/UN/OECD); Ethical risk assessment; Bias/fairness test reports; Accountability framework,,
Development,Unsafe design,Implement safety-by-design principles,"Build predictability, interpretability, corrigibility, and safe fallback mechanisms into models.","Are mechanisms for accuracy, predictability, and safe fallback integrated during development?",Ethics principle mapping (WHO/UN/OECD); Ethical risk assessment; Bias/fairness test reports; Accountability framework,,
Deployment,Weak accountability,Provide redress mechanisms,Patients and clinicians must have channels to challenge AI-driven decisions.,Are channels available for patients to challenge AI-driven decisions?,Ethics principle mapping (WHO/UN/OECD); Ethical risk assessment; Bias/fairness test reports; Accountability framework,,